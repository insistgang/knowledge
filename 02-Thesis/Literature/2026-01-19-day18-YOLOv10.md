**#day18**

今天读 YOLOv10《YOLOv10: Real-Time End-to-End Object Detection》（**NeurIPS 2024**，清华大学，Ao Wang 等）。

**核心痛点**：NMS 是 YOLO 的"阿喀琉斯之踵"

传统 YOLO 依赖 NMS 后处理，带来三个问题：增加推理延迟、需要调参、可能误删正确检测。Day08 DETR 用 Hungarian matching 实现端到端，但 YOLO 系列一直没跟上。

**作者的解法：Consistent Dual Assignments**

训练时同时使用两种分配策略：

- **One-to-many**：像传统 YOLO，提供丰富监督信号
- **One-to-one**：像 DETR，每个 GT 只匹配一个正样本

推理时只用 one-to-one head，天然不需要 NMS。

**效率优化**（Holistic efficiency-accuracy driven design）：

- 轻量级分类头
- 空间通道解耦下采样
- 秩引导的块设计
- 大核卷积
- 部分自注意力模块（PSA）

**关键结果**：

- YOLOv10-S：比 RT-DETR-R18 快 1.8×，参数和 FLOPs 少 2.8×
- YOLOv10-B vs YOLOv9-C：相同性能下，延迟减少 46%，参数减少 25%
- NMS-free 训练为 YOLOv10-S 减少 4.63ms 端到端延迟

**读后感**：

YOLOv10 是 YOLO 系列与 DETR 系列的"合流"。从 YOLOv1 的单阶段革命，到 anchor-based/free 的演进，再到今天的端到端，YOLO 终于实现了真正的 NMS-free 推理。这证明了 one-to-one matching 不是 Transformer 的专利，CNN 架构同样可以端到端。