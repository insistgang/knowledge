#day04 Deep Residual Learning (ResNet)

昨天读Transformer追本溯源，今天继续往回挖——读残差连接的开山之作《Deep Residual Learning for Image Recognition》（ResNet，CVPR 2016，何恺明等）。
前两天读的mHC和MUDDFormer都在"改残差连接"，一个约束防爆炸，一个修立交桥破瓶颈。今天回到源头：残差连接这条路，最初是怎么修出来的？
核心痛点： 网络越深，训练error越高——而且不是过拟合，是优化本身就崩了。
2015年之前，大家发现深网络比浅网络还差。Fig.1显示56层plain网络的训练误差竟然比20层的还高。理论上，56层网络的解空间包含20层的（多出来的层做恒等映射就行），但优化器就是找不到这个解。
作者的解法： 既然学恒等映射H(x)=x这么难，那就别学了——改学残差F(x)=H(x)-x。如果最优解是恒等映射，网络只需要把F(x)推向0，比从头学一个恒等函数容易得多。
一条shortcut，把输入x直接加到输出上：y = F(x) + x。不加参数，不加计算量，梯度直通。
结果：

152层ResNet拿下ImageNet 3.57% top-5 error，碾压所有ensemble
ILSVRC & COCO 2015五项冠军
Fig.7显示残差函数的响应普遍很小，验证了"恒等映射是好的先验"

读后感：
Day01阅读的mHC说残差流太窄要扩展，Day02阅读的MUDD说残差流太堵要修立交桥——但这条路本身，是ResNet在2015年修的。一个简单的"+x"，解锁了深度学习的深度。读开山之作，才明白后来者在这条路上改什么、为什么改。
