#day21 Co-DETR: Towards General Object Detection

今天读Co-DETR《CO-DETR: TOWARDS GENERAL OBJECT DETECTION VIA COLLABORATIVE HYBRID ASSIGNMENTS》（ICCV 2023，南开大学&商汤，Lewei Yao等）。

Day15 DINO达到63.0 AP，但需要针对每个任务单独调参。今天Co-DETR说：用协同混合分配策略，一个模型搞定所有检测任务。

核心痛点：DETR的"专才"困境。

DINO在COCO上SOTA，但换到LVIS或Objects365就需要重新调参。原因是DETR用单一分配策略（one-to-one Hungarian matching），这种策略在不同数据集上表现差异很大——小目标多的数据集、长尾数据集都需要不同策略。

作者的解法：Co-DETR = 协同混合分配 + Query级对比学习。

核心机制：训练时同时使用多种分配策略。

传统DETR只用one-to-one匹配，Co-DETR同时使用：
One-to-one（像DINO）
One-to-many（像传统检测器）
其他辅助分配策略

多个分配分支共享同一个decoder，每个分支独立计算loss，然后汇总。这样模型能同时学习多种匹配方式，推理时只取one-to-one分支的输出。

关键发现：多策略协同，DETR首次突破67 AP。

COCO val（Table 1）：
Co-DETR-R50（12 epochs）：54.6 AP
Co-DETR-R50（50 epochs）：55.8 AP

用Swin-L backbone（Table 1）：
Co-DETR-T（36 epochs）：64.2 AP
Co-DETR-E（36 epochs）：65.6 AP
Co-DETR-X（36 epochs）：67.4 AP

对比DINO-X（Table 1）：
DINO-X：64.5 AP（36 epochs）
Co-DETR-X：67.4 AP（+2.9）

Table 4显示：协同混合分配带来+2.5 AP提升，query-level contrastive learning贡献+0.9 AP。

跨数据集泛化（Table 5）：在Objects365预训练后，COCO上达到67.6 AP，LVIS上达到60.1 AP。

读后感：
Day08 DETR用one-to-one实现端到端，Day18 YOLOv10用一致双重分配去掉NMS。今天Co-DETR说"不要只选一种策略，全都要"。这种"协同学习"的思路后来被广泛应用于多任务学习——让模型同时学习多种方式，然后选择最优组合。Co-DETR证明了DETR不仅能专，更能博。
