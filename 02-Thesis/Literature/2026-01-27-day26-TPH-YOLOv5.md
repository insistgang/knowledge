#day26 TPH-YOLOv5: Object Detection in Drone Images

今天读TPH-YOLOv5《TPH-YOLOV5: OBJECT DETECTION IN DRONE IMAGES》（arXiv 2021，朱瀚等）。

Day25 Gold-YOLO重新设计了YOLO的neck，今天TPH-YOLOv5说：YOLO的prediction head也有问题——用Transformer替换CNN head，专门解决小目标检测。

核心痛点：无人机图像中的"小目标困境"。

无人机拍摄视角高，地面目标在图像中只占几十个像素。传统YOLO的prediction head用CNN（卷积层）做最终预测，局部感受野太小，对小目标"看不见"。

作者的解法：TPH = Transformer Prediction Head。

核心机制：用Transformer替换YOLOv5的prediction head。

YOLOv5原来的head是3个卷积层，TPH-YOLOv5把它换成：
1. C3模块（CSP bottleneck）
2. Transformer encoder block（带自注意力）
3. 最终预测层

Transformer的自注意力机制能捕获全局上下文，让每个位置都能"看到"整张图，不再局限于局部感受野。

还有AFF（Attention Feature Fusion）模块：更好地融合FPN输出的多尺度特征。

关键发现：Transformer head专门解决小目标问题。

VisDrone2021数据集（Table 4）：
TPH-YOLOv5：39.18% AP
YOLOv5：37.28% AP（+1.9%）
YOLOv3：22.38% AP

UAVDT数据集（Table 6）：
TPH-YOLOv5：32.67% AP
YOLOv5：29.96% AP（+2.71%）

Table 3的消融实验显示：仅把YOLOv5的head换成Transformer就能从37.28%提升到38.62%（+1.34%）。

读后感：
Day25 Gold-YOLO重新设计了neck的融合机制，今天TPH-YOLOv5重新设计了head的预测方式。两者都借鉴了Transformer的思想：Gold-YOLO用Transformer做全局融合，TPH-YOLOv5用Transformer扩大感受野。无人机小目标检测是一个专门的子领域，TPH-YOLOv5证明了Transformer的全局建模能力对小目标检测尤其重要——小目标信息少，更需要全局上下文来补充。后来RT-DETR、DINO等工作也印证了这一点。
