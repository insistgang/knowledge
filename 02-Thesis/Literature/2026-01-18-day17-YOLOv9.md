**#day17**

今天读 YOLOv9《YOLOv9: Learning What You Want to Learn Using Programmable Gradient Information》（**ECCV 2024**，**Academia Sinica & 台北科技大学**，Chien-Yao Wang 等）。

**核心痛点**：深层网络的信息瓶颈

基于 information bottleneck theory：数据经过多层变换后，与原始输入的互信息逐渐减小。深层参数可能"学不到有效信息"。

**作者的解法：PGI + GELAN**

**PGI (Programmable Gradient Information)** 包含三个组件：

1. **Main branch**：标准网络，用于推理
2. **Auxiliary reversible branch**：可逆网络，生成可靠梯度
3. **Multi-level auxiliary information**：多层级辅助损失

关键思想：训练时用可逆分支提供"无损"的梯度信号，推理时只用 main branch（无额外开销）。

**GELAN (Generalized ELAN)**：

- 泛化了 YOLOv7 的 ELAN 结构
- 支持任意计算块（CSPNet、RepConv 等）
- 只用常规卷积就超越了 depth-wise convolution 方法

**关键结果**（COCO val2017）：

- YOLOv9-S：46.8 AP，7.1M 参数
- YOLOv9-C：53.0 AP，25.3M 参数
- YOLOv9-E：55.6 AP，57.3M 参数

**核心优势**：相比 YOLOv8，参数减少 49%，计算量减少 43%，同时 AP 提升 0.6%。

**读后感**：

YOLOv9 的独特之处在于从**信息论**角度思考网络设计。之前的改进多是结构层面（anchor-free、attention），而 YOLOv9 关注"梯度信息能否有效传递"。这个视角解释了为什么有些深层网络难以训练——不是梯度消失，而是**信息瓶颈**。