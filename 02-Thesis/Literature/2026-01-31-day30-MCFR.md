#day30 Multi-Scale Contextual Feature Refinement for Object Detection in Remote Sensing Images

今天读《Multi-Scale Contextual Feature Refinement for Object Detection in Remote Sensing Images》（IEEE TGRS 2022，哈尔滨工业大学深圳分校，Zhize Yuan等）。

Day26-28读了三篇小目标检测论文，Day29读了遥感综述，今天MCFR说：遥感检测的核心问题是"多尺度特征对齐"——我来解决这个问题。

核心痛点：遥感图像的"尺度失配"问题。

遥感图像中目标尺寸差异极大：同一个场景里，桥梁可能长达上千像素，而车辆只有几十像素。传统的FPN做跨层特征融合时，直接将上采样的深层特征与浅层特征相加——但两者的语义分布不一致，直接相加会导致特征不对齐。

作者的解法：MCFR = MFR（多尺度特征细化）+ CRF（上下文特征细化）。

两大核心模块：

1. MFR（Multi-scale Feature Refinement）：门控机制控制特征融合。
对不同尺度特征进行1×1卷积对齐通道数
用Sigmoid门控机制自动学习每个尺度的权重
融合后再用残差连接保留原始信息

2. CRF（Contextual Feature Refinement）：注意力机制捕获全局上下文。
用self-attention建模长距离依赖
让小目标能获得全局上下文信息（比如"停车场里的车"）

关键发现：两个模块协同，遥感检测大幅提升。

NWPU VHR-10数据集（Table II）：
MCFR：96.1% mAP
RetinaNet baseline：约89%
提升：约7个百分点

DIOR数据集（Table III）：
MCFR：72.1% mAP
RetinaNet baseline：63.4% mAP（+8.7）

DOTA数据集（Table IV）：
MCFR：77.2% mAP
超越同期SOTA方法

Table V的消融实验证明：
仅添加MFR：mAP提升约4个百分点
仅添加CRF：mAP提升约3个百分点
MFR + CRF：提升约8.7个百分点（1+1>2）

读后感：
Day07 FPN开创了自顶向下的特征金字塔，直接相加实现融合。今天MCFR说"相加之前先对齐"——用门控机制控制融合权重，用注意力机制补充上下文。这种"细粒度特征融合"的思想后来被广泛应用于遥感检测。MCFR证明了：在遥感这种尺度变化剧烈的场景下，简单相加是不够的，需要更智能的融合策略。
