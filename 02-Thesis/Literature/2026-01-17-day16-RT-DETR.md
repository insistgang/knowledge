**#day16**

今天读 RT-DETR《DETRs Beat YOLOs on Real-time Object Detection》（**CVPR 2024**，**百度 & 北大深研院**，**Yian Zhao** 等）。

**核心痛点**：DETR 精度高但太慢，YOLO 快但需要 NMS（引入超参、影响速度）。

**作者的解法：第一个实时端到端检测器**

三大核心改进：

1. **Efficient Hybrid Encoder**：解耦 intra-scale 和 cross-scale 处理
    - AIFI：只在最高层特征 S5 上做 self-attention（减少 35% 延迟，+0.4 AP）
    - CCFF：用 CNN 做跨尺度融合（比 multi-scale Transformer encoder 更高效）
2. **Uncertainty-minimal Query Selection**（§4.3）：
    - 不是简单地用 classification score 选 query
    - 最小化 classification 和 localization 预测分布的差异
    - 贡献 +0.8 AP（Table 4）
3. **灵活速度调节**：调整 **decoder** 层数即可控制速度-精度 tradeoff，无需重训练

**关键结果**（Table 2）：

- RT-DETR-R50：**53.1 AP, 108 FPS**
- RT-DETR-R101：**54.3 AP, 74 FPS**
- 对比 YOLOv8-X：53.9 AP, 50 FPS（RT-DETR 在 end-to-end latency 下更快）

**重要细节**：论文建立了 **end-to-end speed benchmark**（§3.2），将 NMS 时间纳入 YOLO 的延迟计算，这是 RT-DETR "吊打 YOLO" 的关键前提。

**读后感**：

RT-DETR 的核心贡献不只是"让 DETR 变快"，更重要的是**证明了端到端架构在实时场景的可行性**。通过去除 NMS，RT-DETR 避免了超参敏感性问题（Table 1 显示不同 NMS 阈值对精度影响 >1 AP）。后续 YOLOv10 也开始探索端到端训练，说明这个方向已被业界认可。