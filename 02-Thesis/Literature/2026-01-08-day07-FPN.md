#day07 Feature Pyramid Networks (FPN)

今天读FPN《FEATURE PYRAMID NETWORKS FOR OBJECT DETECTION》（CVPR 2017，FAIR，Tsung-Yi Lin等）。

Day06的ViT把图像切块当token，走的是"拆分"路线；今天读的FPN走的是"融合"路线，把不同尺度的特征连成一座金字塔。

核心痛点： 物体检测的多尺度困境——大物体需要浅层高分辨率特征，小物体需要深层强语义特征。传统方案要么只用单尺度特征（Faster R-CNN只看最后一层，小物体看不清），要么搞图像金字塔（多尺度输入，计算量爆炸）。

作者的解法： 既然输入金字塔太慢，那就构建特征金字塔。

FPN的核心是"自顶向下 + 横向连接"：
自顶向下路径：从深层强语义特征开始，逐层上采样
横向连接：每层融合同分辨率的底层特征（1×1卷积后相加）
结果：每层都有"高分辨率 + 强语义"，大车小车都能看清

关键发现：几乎零成本的大幅提升。

相比单尺度baseline（ResNet-50 conv4）：
AP从31.6提升到33.9（+2.3）
小物体APs从13.2提升到17.8（+4.6）——这才是FPN的杀手锏
速度反而更快：FPS从3提升到6.7，因为轻量级2-fc head替代了重的conv5 head

Table 1/2的消融实验证明：横向连接最关键，光有自顶向下路径不够——这说明"分辨率"和"语义"缺一不可。FPN架构后来被Mask R-CNN等众多工作采用。

读后感：
从Day04 ResNet的"+x" shortcut，到Day05 DenseNet的"[x0,x1,…]"密集拼接，再到Day07 FPN的金字塔融合——深度学习的进化史，就是一部"特征连接方式"的探索史。FPN把CNN不同层的特征串成了糖葫芦，每层都能吃到最甜的那一口。这个架构后来成了目标检测的"标配"，连YOLO系列都在用。
