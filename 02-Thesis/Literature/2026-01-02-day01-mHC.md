#day01 mHC: Manifold-Constrained Hyper-Connections

今天阅读的是《mHC: Manifold-Constrained Hyper-Connections》
DeepSeek 12月31日刚发的新鲜论文，给我们跨年夜的礼物吧，主要总结如下：

残差连接是深度学习的基石。它的精髓在于"恒等映射"——浅层信号可以无损直达深层，梯度也能顺畅回传。

Hyper-Connections（HC）想更进一步：把残差流从C维扩展到n×C维，引入可学习的混合矩阵H^res，让不同深度的特征能交互融合。性能确实涨了，但代价是——训练崩了。

当HC堆叠多层时，复合映射H^res不再是恒等映射。实验显示增益幅度飙到3000倍，信号要么爆炸要么消失。27B模型在12k步直接loss spike，梯度范数剧烈震荡。

路修宽了，但却堵车了。

作者提出的mHC的解法核心思想是不改路宽，改交通规则。

将H^res投影到Birkhoff多面体（双随机矩阵流形）上：
所有元素非负，行列和均为1
谱范数≤1，天然防爆炸
矩阵乘法封闭，多层堆叠仍保持双随机性

这样一来，信号传播就变成了特征的"凸组合"——能量守恒，秩序井然。增益幅度从3000降到1.6。

用Sinkhorn-Knopp算法迭代20次实现投影，配合内核融合、选择性重计算、DualPipe通信优化，27B模型仅增加6.7%时间开销。

最终效果
BBH: 43.8 → 51.0 (+7.2%)
DROP: 47.0 → 53.9 (+6.9%)
训练全程稳定，可扩展性验证通过。
