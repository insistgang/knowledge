# 方法部分重写

> **论文**: 基于YOLOv11深度学习的智慧城市井盖状态检测系统
> **章节**: 第2章 基于YOLOv11的井盖状态检测方法
> **版本**: v1.0
> **日期**: 2026-02-07

---

## 2.1 引言

井盖状态检测是一个典型的**小目标精细分类问题**。与通用目标检测任务相比，该任务面临以下独特挑战：

1. **尺度差异显著**：井盖在图像中的占比通常小于1%，属于极小目标
2. **状态细粒度**：需要区分7种状态（完整/破损/缺失/移位/凹陷/遮挡/被占），同类状态样本间差异小
3. **背景复杂干扰**：道路纹理、阴影、相似圆形物体等造成误检
4. **实时性要求**：智慧城市应用需要快速响应（≥30 FPS）

为应对上述挑战，本文在YOLOv11基础上提出三项改进：
- 引入**高分辨率特征金字塔**（P2层）增强小目标感知
- 设计**自适应多尺度特征融合模块**（AMSFF）减少信息损失
- 采用**解耦检测头**（DCH）提升分类精度

---

## 2.2 YOLOv11总体架构

### 2.2.1 网络结构概述

本文方法整体架构如图1所示，由三个核心组件构成：

```
输入图像 I ∈ ℝ^(H×W×3)
    ↓
┌─────────────────────────────────────────┐
│  Backbone: CSPDarknet                    │
│  输出: F = {F₂, F₃, F₄, F₅}             │
└─────────────────────────────────────────┘
    ↓
┌─────────────────────────────────────────┐
│  Neck: 自适应多尺度特征融合 (AMSFF)       │
│  输出: F̃ = {F̃₂, F̃₃, F̃₄, F̃₅}          │
└─────────────────────────────────────────┘
    ↓
┌─────────────────────────────────────────┐
│  Head: 解耦检测头 (DCH)                   │
│  输出: {p_i, b_i, s_i}                   │
└─────────────────────────────────────────┘
```

### 2.2.2 数学形式化定义

设输入图像为 $I \in \mathbb{R}^{H \times W \times 3}$，其中 $H$ 和 $W$ 分别表示图像的高和宽。检测网络可建模为以下映射函数：

$$
f_{\theta}: \mathbb{R}^{H \times W \times 3} \rightarrow \mathcal{Y}
$$

其中 $\theta$ 表示网络参数，$\mathcal{Y}$ 为预测结果集合。

**主干网络**提取多尺度特征：

$$
\mathcal{F} = f_{\phi}(I) = \{F_2, F_3, F_4, F_5\}
$$

其中 $F_i \in \mathbb{R}^{H/2^i \times W/2^i \times C_i}$ 表示stride为 $2^i$ 的特征图。

**颈部网络**进行特征融合：

$$
\tilde{\mathcal{F}} = f_{\psi}(\mathcal{F}) = \{\tilde{F}_2, \tilde{F}_3, \tilde{F}_4, \tilde{F}_5\}
$$

**检测头**输出最终预测：

$$
\mathcal{Y} = f_{\omega}(\tilde{\mathcal{F}}) = \{(p_j, b_j, s_j)\}_{j=1}^{M}
$$

其中 $p_j \in \mathbb{R}^7$ 为7类状态概率，$b_j \in \mathbb{R}^4$ 为边界框坐标，$s_j \in [0,1]$ 为置信度。

---

## 2.3 改进的多层次特征融合

### 2.3.1 问题分析

传统FPN采用自顶向下路径和横向连接进行特征融合：

$$
P_i^{FPN} = \text{Conv}(F_i \oplus \text{Upsample}(P_{i+1}^{FPN}))
$$

该方式存在两个问题：
1. **递归信息损失**：跨层信息需要逐层传递，导致信息衰减
2. **固定融合权重**：各层级特征采用固定权重相加，忽略场景差异性

### 2.3.2 高分辨率特征金字塔

针对小目标检测问题，本文在标准FPN的$\{P_3, P_4, P_5\}$基础上，引入**P2层**（stride=4）：

$$
P_2 = \text{Conv}_{1\times1}\left(F_2\right) \oplus \text{Conv}_{1\times1}\left(\text{Upsample}(F_3)\right)
$$

P2层特征分辨率为 $H/4 \times W/4$，相比P3层保留了4倍空间细节。

**理论分析**：设井盖在原图中尺寸为 $h_{obj} \times w_{obj}$，则在特征图中的尺寸为：

$$
s_i = \left\lceil \frac{h_{obj}}{2^i} \right\rceil \times \left\lceil \frac{w_{obj}}{2^i} \right\rceil
$$

对于 $32 \times 32$ 像素的井盖，在P2层中为 $8 \times 8$，在P3层中仅为 $4 \times 4$。

### 2.3.3 自适应多尺度特征融合模块

本文提出的AMSFF模块直接聚合所有层级信息，避免递归传递损失：

$$
\tilde{F}_i = \text{Conv}\left( \sum_{j=2}^{5} w_{ij} \cdot \text{Align}(F_j, s_i) \right)
$$

其中 $\text{Align}(F_j, s_i)$ 将 $F_j$ 对齐到stride=$2^i$的尺度：

$$
\text{Align}(F_j, s_i) = \begin{cases}
\text{Upsample}(F_j), & j > i \\
F_j, & j = i \\
\text{Downsample}(F_j), & j < i
\end{cases}
$$

**门控权重学习**：融合权重 $w_{ij}$ 通过网络自动学习：

$$
w_{ij} = \frac{\exp(g_{ij})}{\sum_{k=2}^{5} \exp(g_{ik})}
$$

其中门控值 $g_{ij}$ 由轻量级门控网络计算：

$$
g_{ij} = \sigma\left( W_g \cdot \text{GlobalAvgPool}\left( \text{Concat}(F_i, F_j) \right) \right)
$$

**残差连接**：为保留原始特征信息，AMSFF引入残差连接：

$$
\tilde{F}_i = F_i \oplus \text{Conv}\left( \sum_{j \neq i} w_{ij} \cdot \text{Align}(F_j, s_i) \right)
$$

### 2.3.4 时空感知注意力机制

在AMSFF输出基础上，进一步应用时空感知注意力（STAA）增强特征表达：

$$
F_i^{att} = \text{STAA}(F_i) = \text{SA}(F_i) \odot \text{TA}(F_i)
$$

**空间注意力分支**：

$$
\text{SA}(F_i) = \sigma\left( f^{7\times7}\left( [\text{AvgPool}_{c}(F_i); \text{MaxPool}_{c}(F_i)] \right) \right)
$$

沿通道维度进行池化，突出空间位置的重要性。

**通道注意力分支**：

$$
\text{TA}(F_i) = \sigma\left( \text{MLP}(\text{GAP}(F_i)) \odot \text{MLP}(\text{GMP}(F_i)) \right)
$$

通过全局池化建模通道间的依赖关系。

---

## 2.4 优化的检测头

### 2.4.1 问题分析

YOLO系列传统检测头采用**耦合设计**，分类和回归任务共享部分参数：

$$
\begin{aligned}
F_{shared} &= \text{Conv}_{3\times3}(F_i) \\
p_i &= \text{Softmax}(W_{cls} \cdot F_{shared}) \\
b_i &= \text{Sigmoid}(W_{reg} \cdot F_{shared})
\end{aligned}
$$

这种设计存在两个问题：
1. **任务冲突**：分类关注"是什么"，回归关注"在哪里"，两者优化方向不同
2. **特征竞争**：共享特征空间导致两类任务相互干扰

### 2.4.2 解耦检测头设计

本文采用**完全解耦**的检测头结构：

$$
\begin{aligned}
\text{分类分支:} \quad p_i &= \text{Softmax}\left( W_{cls} \cdot \text{ReLU}(\text{BN}(F_{cls})) \right) \\
\text{回归分支:} \quad b_i &= \text{Sigmoid}\left( W_{reg} \cdot \text{ReLU}(\text{BN}(F_{reg})) \right)
\end{aligned}
$$

其中 $F_{cls}$ 和 $F_{reg}$ 分别为分类和回归分支的独立特征：

$$
\begin{aligned}
F_{cls} &= \text{Conv}_{3\times3}^{(2)} \circ \text{Conv}_{1\times1}(F_i^{att}) \\
F_{reg} &= \text{Conv}_{3\times3}^{(2)} \circ \text{Conv}_{1\times1}(F_i^{att})
\end{aligned}
$$

参数完全独立：$\theta_{cls} \cap \theta_{reg} = \emptyset$

### 2.4.3 动态标签分配

为解决正负样本分配问题，本文采用基于**最优传输**的动态标签分配策略：

**步骤1**：计算预测框与真值的匹配代价：

$$
C_{ij} = \lambda_1 \mathcal{L}_{cls}(p_i, c_j^*) + \lambda_2 \mathcal{L}_{iou}(b_i, b_j^*)
$$

**步骤2**：为每个真值动态选择Top-K正样本：

$$
k_j = \left\lfloor \sum_{i=1}^{N} \mathbb{1}[\text{IoU}(b_i, b_j^*) > 0.5] \right\rfloor
$$

**步骤3**：求解最优传输问题：

$$
\min_{T_{ij}} \sum_{i,j} T_{ij} C_{ij}, \quad s.t. \sum_j T_{ij} = 1, \sum_i T_{ij} = k_j
$$

---

## 2.5 损失函数

本文总损失函数由四部分组成：

$$
\mathcal{L} = \lambda_1 \mathcal{L}_{cls} + \lambda_2 \mathcal{L}_{bbox} + \lambda_3 \mathcal{L}_{dfl} + \lambda_4 \mathcal{L}_{iou}
$$

### 2.5.1 分类损失

采用二元交叉熵损失（VFL变体）：

$$
\mathcal{L}_{cls} = -\frac{1}{N}\sum_{i=1}^{N} \left[ q_i \log(p_i) + (1-q_i) \log(1-p_i) \right] \cdot |p_i - q_i|^{\beta}
$$

其中 $q_i \in \{0, 1\}$ 为真值标签，$\beta$ 为聚焦参数。

### 2.5.2 边界框回归损失

采用**CIoU Loss**综合考虑重叠度、中心距离和长宽比：

$$
\mathcal{L}_{CIoU} = 1 - IoU + \frac{\rho^2(b, b^{gt})}{c^2} + \alpha v
$$

其中：
- $IoU = \frac{|b \cap b^{gt}|}{|b \cup b^{gt}|}$
- $\rho(b, b^{gt})$ 为中心点欧氏距离
- $c$ 为最小包围盒对角线长度
- $v$ 衡量长宽比一致性

### 2.5.3 分布焦点损失

采用DFL将边界框回归建模为分布预测：

$$
\mathcal{L}_{DFL} = -\sum_{i=1}^{4} \left( (y_i + \delta) \log(\hat{y}_i) + (1-y_i-\delta) \log(1-\hat{y}_i) \right)
$$

其中 $\delta \in [0, 1]$ 为连续标签偏移量。

---

## 2.6 本章小结

本章详细介绍了本文提出的基于YOLOv11的井盖状态检测方法。主要贡献包括：

1. **高分辨率特征金字塔**：引入P2层增强小目标感知能力
2. **自适应多尺度特征融合模块**：通过门控机制实现跨层级信息的自适应聚合
3. **时空感知注意力**：结合空间注意力和通道注意力增强特征表达
4. **解耦检测头**：分离分类和回归任务，减少相互干扰

第3章将通过大量实验验证以上改进的有效性。

---

## 附录：数学符号索引

| 符号 | 定义 | 首次出现位置 |
|------|------|-------------|
| $I$ | 输入图像 | 2.2.1 |
| $\mathcal{F}$ | 多尺度特征集合 | 2.2.1 |
| $F_i$ | 第i层特征图 | 2.2.1 |
| $\tilde{F}_i$ | 融合后特征图 | 2.3.3 |
| $P_i$ | 第i层预测特征 | 2.3.2 |
| $w_{ij}$ | 融合权重 | 2.3.3 |
| $p_i$ | 类别概率 | 2.2.1 |
| $b_i$ | 边界框 | 2.2.1 |
| $s_i$ | 置信度 | 2.2.1 |
| $\mathcal{L}$ | 总损失 | 2.5 |
| $IoU$ | 交并比 | 2.5.2 |

---

*文档版本: v1.0*
*最后更新: 2026-02-07*
*维护者: Technical Architect*
