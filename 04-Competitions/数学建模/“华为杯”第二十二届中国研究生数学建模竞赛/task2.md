# Task2：源域故障诊断

## 4.1 问题分析

### 4.1.1 问题建模

基于Task1提取的50维特征向量，构建多分类器实现轴承故障类型的自动识别。将源域故障诊断建模为21分类监督学习问题：

设输入特征向量为 $\mathbf{x} = [x_1, x_2, ..., x_{50}]^T \in \mathbb{R}^{50}$，输出为故障类别标签：

y \in {DE_B_0.007, DE_B_0.014, ..., FE_OR_0.021, N}

包含以下故障类别：

- **DE滚动体故障**：4种尺寸（0.007", 0.014", 0.021", 0.028"）
- **DE内圈故障**：4种尺寸（0.007", 0.014", 0.021", 0.028"）
- **DE外圈故障**：3种尺寸（0.007", 0.014", 0.021"）
- **FE滚动体故障**：3种尺寸（0.007", 0.014", 0.021"）
- **FE内圈故障**：3种尺寸（0.007", 0.014", 0.021"）
- **FE外圈故障**：3种尺寸（0.007", 0.014", 0.021"）
- **正常状态**：N

### 4.1.2 数据集划分与评价指标

测试集共721个样本，类别分布不均衡，其中：

- DE_OR_0.007和DE_OR_0.021样本数最多（各107个）
- FE_OR_0.007样本数为54个
- 大部分类别样本数为18-36个
- 正常状态N仅17个样本

评价指标包括：

- **准确率（Accuracy）**：$\frac{正确分类样本数}{总样本数}$
- **精确率（Precision）**：$P_i = \frac{TP_i}{TP_i + FP_i}$
- **召回率（Recall）**：$R_i = \frac{TP_i}{TP_i + FN_i}$
- **F1分数**：$F1_i = \frac{2P_i R_i}{P_i + R_i}$
- **ROC-AUC**：多分类ROC曲线下面积
- **Log Loss**：$-\frac{1}{N}\sum_{i=1}^{N}\sum_{c=1}^{21} y_{ic} \log(p_{ic})$

## 4.2 模型建立与求解

### 4.2.1 XGBoost模型

#### 4.2.1.1 算法原理

XGBoost通过梯度提升树实现多分类，目标函数为：

$$\mathcal{L}^{(t)} = \sum_{i=1}^n l(y_i, \hat{y}_i^{(t-1)} + f_t(x_i)) + \Omega(f_t)$$

其中$l$为多分类softmax损失函数：

$$l(y_i, \hat{y}*i) = -\sum*{k=1}^{21} y_{ik} \log(\text{softmax}(\hat{y}_{ik}))$$

正则化项：$\Omega(f_t) = \gamma T + \frac{1}{2}\lambda \sum_{j=1}^T w_j^2$

#### 4.2.1.2 实验结果分析

XGBoost取得了最优性能：

- **准确率**：94%
- **宏平均F1**：0.94
- **加权平均F1**：0.94
- **ROC-AUC**：0.9968
- **Log Loss**：0.2347

**各类别表现分析**：

- 表现最优：FE_B_0.021（F1=1.00）、FE_IR_0.007（F1=1.00）
- 表现良好：DE_IR_0.014（F1=0.97）、DE_OR_0.021（F1=0.96）
- 相对较弱：DE_IR_0.021（F1=0.90）、DE_IR_0.028（F1=0.91）

### 4.2.2 随机森林模型

#### 4.2.2.1 算法原理

随机森林通过Bagging集成多个决策树，每棵树在随机特征子集上训练：

$$\hat{y} = \text{mode}{T_1(\mathbf{x}), T_2(\mathbf{x}), ..., T_K(\mathbf{x})}$$

信息增益计算：$IG(D, A) = H(D) - \sum_{v} \frac{|D_v|}{|D|} H(D_v)$

其中熵：$H(D) = -\sum_{i=1}^{21} p_i \log_2 p_i$

#### 4.2.2.2 实验结果分析

随机森林性能中等：

- **准确率**：73%
- **宏平均F1**：0.73
- **加权平均F1**：0.73
- **ROC-AUC**：0.9778
- **Log Loss**：1.0074

**性能特点**：

- 类别间表现差异较大
- 类别3（DE_B_0.028）精确率最高（0.96）
- 类别6（DE_IR_0.021）和类别19表现较差

### 4.2.3 k近邻算法（kNN）

#### 4.2.3.1 算法原理

kNN通过计算测试样本与训练样本的距离，选择k个最近邻进行投票分类：

$$\hat{y} = \arg\max_{c} \sum_{i \in N_k(\mathbf{x})} \mathbb{I}(y_i = c)$$

距离度量采用欧几里得距离：$d(\mathbf{x}_i, \mathbf{x}_j) = |\mathbf{x}_i - \mathbf{x}_j|_2$

#### 4.2.3.2 实验结果分析

kNN性能较差：

- **准确率**：44%
- **宏平均F1**：0.45
- **ROC-AUC**：0.8388
- **平均Log Loss**：15.66（交叉验证）
- **最终Log Loss**：8.80

**性能分析**：

- 在高维特征空间中，kNN容易受到"维度诅咒"影响
- 类别不平衡进一步恶化了性能
- FE类别相对表现较好，DE_B类别表现最差

### 4.2.4 支持向量机（SVM）

#### 4.2.4.1 算法原理

采用一对多策略处理多分类问题，第c类的决策函数：

$$f_c(\mathbf{x}) = \sum_{i=1}^n \alpha_i y_i K(\mathbf{x}_i, \mathbf{x}) + b_c$$

使用RBF核函数：$K(\mathbf{x}_i, \mathbf{x}_j) = \exp(-\gamma|\mathbf{x}_i - \mathbf{x}_j|^2)$

优化问题： $$\min_{\mathbf{w}, b, \xi} \frac{1}{2}|\mathbf{w}|^2 + C\sum_{i=1}^n \xi_i$$

#### 4.2.4.2 实验结果分析

SVM性能不理想：

- **准确率**：44%
- **宏平均F1**：0.39
- **ROC-AUC**：0.8997
- **平均Log Loss**：2.65（交叉验证）
- **最终Log Loss**：1.75

**问题分析**：

- 部分类别召回率为0（如DE_IR_0.021、FE_OR_0.021）
- 类别不平衡导致决策边界偏向主要类别
- 高维特征空间中线性不可分问题严重

### 4.2.5 算法性能对比

| 算法          | 准确率   | 宏平均F1 | ROC-AUC    | Log Loss   | 运行时间(s) |
| ------------- | -------- | -------- | ---------- | ---------- | ----------- |
| **XGBoost**   | **0.94** | **0.94** | **0.9968** | **0.2347** | 31.2        |
| Random Forest | 0.73     | 0.73     | 0.9778     | 1.0074     | 93.5        |
| kNN           | 0.44     | 0.45     | 0.8388     | 8.8025     | 6.0         |
| SVM           | 0.44     | 0.39     | 0.8997     | 1.7468     | 82.3        |

## 4.3 结果分析与讨论

### 4.3.1 模型性能差异分析

**XGBoost表现最优的原因**：

1. **梯度提升机制**：能够有效处理复杂的非线性特征关系
2. **正则化控制**：L1和L2正则化防止过拟合
3. **处理不平衡数据**：通过样本权重调整适应类别不平衡
4. **特征重要性**：自动学习特征权重，突出关键诊断特征

**其他算法的局限性**：

- **Random Forest**：在高维稀疏特征上容易过拟合
- **kNN**：受维度诅咒和噪声影响严重
- **SVM**：多分类策略和核函数选择不当

### 4.3.2 类别识别难度分析

**易识别类别特征**：

- FE类别整体表现较好，可能由于样本相对集中
- 较大故障尺寸（0.021", 0.028"）识别效果好
- 外圈故障整体识别率高于内圈和滚动体故障

**难识别类别原因**：

- DE_IR_0.021等类别可能特征相似度高
- 小尺寸故障（0.007"）特征不明显
- 样本不平衡加剧识别困难

### 4.3.3 特征有效性验证

XGBoost的优异性能验证了Task1特征提取的有效性：

- 50维特征能够有效区分21种故障状态
- 多域特征组合提供了充分的判别信息
- 特征标准化和选择策略合理

## 4.4 本章小结

### 4.4.1 主要成果

1. **算法对比验证**：通过四种主流机器学习算法的系统对比，确定XGBoost为最优解决方案，准确率达到94%。
2. **多分类问题解决**：成功解决了21分类的复杂轴承故障诊断问题，为实际工程应用提供了可行方案。
3. **性能评估体系**：建立了包含准确率、F1分数、ROC-AUC、Log Loss等多维度评价指标，全面评估模型性能。
4. **算法适用性分析**：深入分析了不同算法在轴承故障诊断中的适用性和局限性。

### 4.4.2 技术贡献

1. **梯度提升优化**：XGBoost在多分类任务中表现出色，Log Loss仅0.2347，显著优于其他算法。
2. **类别不平衡处理**：通过算法对比发现XGBoost在处理不平衡数据集方面的优势。
3. **计算效率平衡**：XGBoost在保持高精度的同时，计算时间相对合理（31.2秒）。

### 4.4.3 工程应用价值

1. **实用性验证**：94%的准确率满足实际工程应用需求。
2. **鲁棒性确认**：在类别不平衡和高维特征条件下仍保持稳定性能。
3. **可扩展性**：为后续迁移学习提供了可靠的源域模型基础。

### 4.4.4 为Task3迁移学习的准备

1. **基线性能建立**：94%的源域准确率为迁移效果评估提供基准。
2. **模型结构确定**：XGBoost的树结构有利于特征重要性分析和迁移。
3. **特征有效性确认**：验证了Task1提取的50维特征的充分性和有效性。

本章通过系统的模型对比和性能分析，确立了XGBoost作为源域故障诊断的最优模型，为后续的跨域迁移学习奠定了坚实的技术基础。